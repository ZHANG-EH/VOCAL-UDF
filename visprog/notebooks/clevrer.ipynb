{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-01-17 17:20:44,059] [INFO] [real_accelerator.py:110:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from IPython.core.display import HTML\n",
    "from functools import partial\n",
    "import cv2\n",
    "\n",
    "from visprog.engine.utils import ProgramGenerator, ProgramInterpreter\n",
    "from visprog.prompts.clevrer import create_prompt\n",
    "import base64\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering LOC step\n",
      "Registering TRACK step\n",
      "Registering LEFT step\n",
      "Registering RIGHT step\n",
      "Registering TOP step\n",
      "Registering BOTTOM step\n",
      "Registering GRAY step\n",
      "Registering RED step\n",
      "Registering BLUE step\n",
      "Registering GREEN step\n",
      "Registering BROWN step\n",
      "Registering PURPLE step\n",
      "Registering CYAN step\n",
      "Registering YELLOW step\n",
      "Registering CUBE step\n",
      "Registering SPHERE step\n",
      "Registering CYLINDER step\n",
      "Registering RUBBER step\n",
      "Registering METAL step\n",
      "Registering LEFTOF step\n",
      "Registering RIGHTOF step\n",
      "Registering FRONTOF step\n",
      "Registering BEHIND step\n",
      "Registering EVENT step\n",
      "Registering BEFORE step\n",
      "Registering EVAL step\n",
      "Registering RESULT step\n"
     ]
    }
   ],
   "source": [
    "module_list = [\"LOC\", \"TRACK\", \"GRAY\", \"RED\", \"BLUE\", \"GREEN\", \"CUBE\", \"SPHERE\", \"RUBBER\", \"LEFT\", \"TOP\", \"LEFTOF\", \"FRONTOF\", \"EVENT\", \"BEFORE\", \"EVAL\", \"RESULT\"]\n",
    "use_precomputed = False\n",
    "interpreter = ProgramInterpreter(dataset='clevrer', use_precomputed=use_precomputed, module_list=module_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog = \"\"\"OBJ0=LOC(video=VIDEO,object='object')\n",
    "OBJT=TRACK(object=OBJ0)\n",
    "PRED0=RED(object=OBJT,var='o0')\n",
    "PRED1=RUBBER(object=OBJT,var='o0')\n",
    "PRED2=TOP(object=OBJT,var='o1')\n",
    "PRED3=FRONTOF(object1=OBJT,var1='o0',object2=OBJT,var2='o1')\n",
    "EVENT0=EVENT(predicates=[PRED0,PRED1,PRED2,PRED3],min_duration=1)\n",
    "PRED4=FRONTOF(object1=OBJT,var1='o1',object2=OBJT,var2='o0')\n",
    "EVENT1=EVENT(predicates=[PRED4],min_duration=1)\n",
    "EVENT2=BEFORE(event1=EVENT0, event2=EVENT1)\n",
    "PRED5=TOP(object=OBJT,var='o2')\n",
    "PRED6=LEFT(object=OBJT,var='o2')\n",
    "EVENT3=EVENT(predicates=[PRED5,PRED6],min_duration=25)\n",
    "EVENT4=BEFORE(event1=EVENT2, event2=EVENT3)\n",
    "ANSWER0=EVAL(expr=\"'yes' if len({EVENT4}) else 'no'\")\n",
    "FINAL_RESULT=RESULT(var=ANSWER0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC\n",
      "TRACK\n",
      "RED\n",
      "RUBBER\n",
      "TOP\n",
      "FRONTOF\n",
      "EVENT\n",
      "FRONTOF\n",
      "EVENT\n",
      "BEFORE\n",
      "TOP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mmfs1/gscratch/balazinska/enhaoz/VOCAL-UDF/ByteTrack/yolox/tracker/byte_tracker.py:129: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  ret[2] /= ret[3]\n",
      "/mmfs1/gscratch/balazinska/enhaoz/VOCAL-UDF/ByteTrack/yolox/tracker/byte_tracker.py:107: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret[2] *= ret[3]\n",
      "/mmfs1/gscratch/balazinska/enhaoz/VOCAL-UDF/ByteTrack/yolox/tracker/byte_tracker.py:107: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret[2] *= ret[3]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:06<00:00,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEFT\n",
      "EVENT\n",
      "BEFORE\n",
      "EVAL\n",
      "RESULT\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "output = []\n",
    "for vid in tqdm([11]):\n",
    "    if not use_precomputed:\n",
    "        cap = cv2.VideoCapture(\n",
    "            os.path.join(\n",
    "                '/gscratch/balazinska/enhaoz/VOCAL-UDF/data',\n",
    "                'clevrer', \n",
    "                f'video_{str(vid//1000*1000).zfill(5)}-{str((vid//1000+1)*1000).zfill(5)}', \n",
    "                f\"video_{str(vid).zfill(5)}.mp4\"\n",
    "            )\n",
    "        )\n",
    "        video = []\n",
    "        fid = 0\n",
    "        while True:\n",
    "            ret, frame = cap.read()  # Read the next frame from the video\n",
    "            if not ret:\n",
    "                break  # Break the loop if there are no more frames\n",
    "\n",
    "            # Convert the frame from BGR (OpenCV format) to RGB (PIL format)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            # Convert the frame to a PIL Image and append to the list\n",
    "            image = Image.fromarray(frame)\n",
    "            image.thumbnail((640,640),Image.Resampling.LANCZOS)\n",
    "            video.append(image)\n",
    "            fid += 1\n",
    "    init_state = dict(\n",
    "        VIDEO=video,\n",
    "        vid=vid\n",
    "    )\n",
    "    result, prog_state = interpreter.execute(prog,init_state,inspect=False)\n",
    "    if result == 'yes':\n",
    "        output.append(vid)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
